# === test.py ===
import os

def dump_project_code(project_root, output_file="project_code_dump.txt"):
    with open(output_file, "w", encoding="utf-8") as out:
        for root, _, files in os.walk(project_root):
            # 跳过 __pycache__
            if "__pycache__" in root:
                continue
            for file in files:
                if file.endswith(".py"):
                    file_path = os.path.join(root, file)
                    rel_path = os.path.relpath(file_path, project_root)
                    out.write(f"# === {rel_path} ===\n")
                    with open(file_path, "r", encoding="utf-8") as f:
                        out.write(f.read())
                    out.write("\n\n")

# 使用示例：设定你的项目目录路径
project_path = "/home/cnic/aiagent1"  # 修改成你的实际路径
dump_project_code(project_path)


# === main.py ===
# main.py
import sys
import agent

def main():
    if len(sys.argv) > 1:
        query = " ".join(sys.argv[1:])
    else:
        query = input("请输入查询: ")
    agent.chat(query)

if __name__ == '__main__':
    main()


# === agent.py ===
#! /usr/bin/env python3
import re
import json
import datetime
import requests
import os  
import hashlib
import config 
import dateparser
from django.conf import settings

from analysis.single_series import analyze_single_series
from analysis.multi_series import analyze_multi_series
from output.report_generator import generate_report_single, generate_report_multi
from output.visualization import generate_echarts_html_single, generate_echarts_html_multi

AIOPS_BACKEND_DOMAIN = 'https://aiopsbackend.cstcloud.cn'
LLM_URL = 'http://10.16.1.16:58000/v1/chat/completions'

AUTH = ('chelseyyycheng@outlook.com', 'UofV1uwHwhVp9tcTue')
CACHE_DIR = "cached_data"
os.makedirs(CACHE_DIR, exist_ok=True)

def parse_time_expressions(raw_text:str):
    """
    从用户输入中提取多个时间表达式，逐一用 dateparser.parse 解析。
    返回一个列表，每个元素是 {start_ts, end_ts, error}，单位为 int秒 (整天或近似区间)
    
    - 不使用硬编码的“这周一 => 某年月日”等逻辑，而是让 dateparser 自动识别中文/英文自然语言
    - 为了简单，此处默认:
       如果解析出的datetime成功 => start=该日0点, end=该日23:59:59
       若用户写了带“到/至/到/至/~/--”之类，也可扩展解析区间 (此处演示略)
    - 若解析失败，则 error 填写信息
    """
    # 用一个简单正则来拆分可能的时间表达，如 “这周一和上周一” -> ["这周一","上周一"]
    # 如果用户只写一句，也能只得到1个
    # （可根据需要再提升复杂度，如处理 "2023-03-01到2023-03-05"）
    segments = re.split(r'[,\uFF0C\u3001\u0026\u002C\u002F\u0020\u0026\u2014\u2013\u2014\u006E\u005E]|和|与|及|还有|、', raw_text)
    # 以上只是示例，用各种分隔符号拆分。可根据需求继续完善
    
    results = []
    for seg in segments:
        seg = seg.strip()
        if not seg:
            continue

        # 调用 dateparser
        dt = dateparser.parse(seg, languages=['zh','en'], settings={"PREFER_DATES_FROM":"past"})
        if dt is None:
            # 解析失败
            results.append({"start":0, "end":0, "error":f"无法解析: {seg}"})
        else:
            # 如果只要整天 => 将dt对齐到0点~23:59:59
            day_s = datetime.datetime(dt.year, dt.month, dt.day, 0,0,0)
            day_e = datetime.datetime(dt.year, dt.month, dt.day, 23,59,59)
            results.append({
                "start": int(day_s.timestamp()),
                "end":   int(day_e.timestamp()),
                "error": ""
            })
    return results

def shorten_tool_result(res):
    """
    将工具调用结果res(可能是list、dict、或长字符串)进行简要化, 避免累积大段数据进入下轮对话.
    """
    if isinstance(res, list):
        # 说明可能是时序数据 => 只显示长度
        return f"[List len={len(res)}]"
    elif isinstance(res, dict):
        # 可能是 {analysis:..., report:..., html:...}
        # 只取一部分
        summary = {}
        for k,v in res.items():
            if isinstance(v, list):
                summary[k] = f"[List len={len(v)}]"
            elif isinstance(v, str) and len(v)>300:
                summary[k] = v[:300] + f"...(omitted, length={len(v)})"
            else:
                summary[k] = v
        return json.dumps(summary, ensure_ascii=False)
    elif isinstance(res, str) and len(res)>300:
        return res[:300] + f"...(omitted, length={len(res)})"
    else:
        return str(res)



###############################################################################
# 一、定义“工具”列表 (更精确)
###############################################################################
tools = [
     {
        "name":"解析用户自然语言时间",
        "description":"返回一个list，每个元素是{start, end, error}. 如果不确定，可向用户澄清。",
        "parameters":{
            "type":"object",
            "properties":{
                "raw_text":{"type":"string"}
            },
            "required":["raw_text"]
        }
    },
    {  
        "name": "请求智能运管后端Api，获取指标项的时序数据",
        "description": "从后端或本地缓存获取IP在指定时间范围(field)的时序数据(list of [int_ts, val])。注意start/end必须是形如'YYYY-MM-DD HH:MM:SS'的确定时间。",
        "parameters": {
            "type": "object",
            "properties": {
                "ip": {
                    "type": "string",
                    "description": "要查询的 IP，如 '192.168.0.110'"
                },
                "start": {
                    "type": "string",
                    "description": "开始时间，格式 '2025-03-24 00:00:00'"
                },
                "end": {
                    "type": "string",
                    "description": "结束时间，格式 '2025-03-24 23:59:59'"
                },
                "field": {
                    "type": "string",
                    "description": "监控项名称，如 'cpu_rate'"
                }
            },
            "required": ["ip","start","end","field"]
        }
    },
    {
        "name": "请求智能运管后端Api，查询监控实例有哪些监控项",
        "description": "返回指定IP下可用的监控项列表（可选项）",
        "parameters": {
            "type": "object",
            "properties": {
                "service": {
                    "type": "string",
                    "description": "系统服务名称 (一般填 '主机监控')"
                },
                "instance": {
                    "type": "string",
                    "description": "监控实例 IP"
                }
            },
            "required": ["service","instance"]
        }
    },
    {
        "name": "请求智能运管后端Api，查询监控服务的资产情况和监控实例",
        "description": "查询一个监控服务的所有资产/IP等信息",
        "parameters": {
            "type": "object",
            "properties": {
                "service": {
                    "type": "string",
                    "description": "要查询的系统服务名称"
                }
            },
            "required": ["service"]
        }
    },
    {
        "name": "请求智能运管后端Api，查询监控实例之间的拓扑关联关系",
        "description": "查询指定IP的上联、下联监控实例等信息",
        "parameters": {
            "type": "object",
            "properties": {
                "service": {
                    "type": "string",
                    "description": "系统服务名称"
                },
                "instance_ip": {
                    "type": "string",
                    "description": "监控实例IP"
                }
            },
            "required": ["service","instance_ip"]
        }
    },
    {
        "name": "单序列异常检测(文件)",
        "description": "对单序列 [int_ts,val] 进行多方法分析, 生成报告和ECharts HTML",
        "parameters": {
            "type": "object",
            "properties": {
                "ip":    {"type": "string"},
                "field": {"type": "string"},
                "start": {"type": "string"},
                "end":   {"type": "string"}
            },
            "required": ["ip","field","start","end"]
        }
    },
    {
        "name": "多序列对比异常检测(文件)",
        "description": "对两组 [int_ts,val] 进行对比分析, 生成报告和ECharts HTML",
        "parameters": {
            "type": "object",
            "properties": {
                "ip1":    {"type": "string"},
                "field1": {"type": "string"},
                "start1": {"type": "string"},
                "end1":   {"type": "string"},
                "ip2":    {"type": "string"},
                "field2": {"type": "string"},
                "start2": {"type": "string"},
                "end2":   {"type": "string"}
            },
            "required": ["ip1","field1","start1","end1","ip2","field2","start2","end2"]
        }
    }
]


###############################################################################
# 二、后端数据 API + 本地缓存
###############################################################################

def monitor_item_list(ip):
    """示例: 拿到此IP可用的监控项。"""
    url = f'{AIOPS_BACKEND_DOMAIN}/api/v1/monitor/mail/machine/field/?instance={ip}'
    resp = requests.get(url=url, auth=AUTH)
    if resp.status_code == 200:
        items = json.loads(resp.text)
        result = {}
        for x in items:
            result[x.get('field')] = x.get('purpose')
        return result
    else:
        return f"查询监控项失败: {resp.status_code} => {resp.text}"

def get_service_asset(service):
    """示例: 查询某service下的资产信息"""
    url = f'{AIOPS_BACKEND_DOMAIN}/api/v1/property/mail/?ordering=num_id&page=1&page_size=2000'
    resp = requests.get(url=url, auth=AUTH)
    if resp.status_code == 200:
        text = json.loads(resp.text)
        results = text.get('results',[])
        item_list = []
        for r in results:
            # 做一些清洗
            r["category"] = r.get("category",{}).get("name")
            r["ip_set"] = [_.get("ip") for _ in r.get('ip_set',[])]
            for k in ["num_id","creation","modification","remark","sort_weight","monitor_status"]:
                r.pop(k, None)
            # 移除空值
            for k,v in list(r.items()):
                if not v or v == "无":
                    r.pop(k)
            item_list.append(r)
        return item_list
    else:
        return f"查询失败: {resp.status_code} => {resp.text}"

def get_service_asset_edges(service, instance_ip):
    """示例: 拓扑查询"""
    url = f'{AIOPS_BACKEND_DOMAIN}/api/v1/property/mail/topology/search?instance={instance_ip}'
    resp = requests.get(url=url, auth=AUTH)
    if resp.status_code == 200:
        return json.loads(resp.text)
    else:
        return f"查询拓扑失败: {resp.status_code} => {resp.text}"
    

def _cache_filename(ip, start_ts, end_ts, field):
    key = f"{ip}_{start_ts}_{end_ts}_{field}"
    h = hashlib.md5(key.encode('utf-8')).hexdigest()
    return os.path.join(CACHE_DIR, f"{h}.json")

def fetch_data_from_backend(ip:str, start_ts:int, end_ts:int, field:str):
    """
    访问后端, 返回 list of [int_ts, float_val]
    """
    url = f"{AIOPS_BACKEND_DOMAIN}/api/v1/monitor/mail/metric/format-value/?start={start_ts}&end={end_ts}&instance={ip}&field={field}"
    resp = requests.get(url, auth=AUTH)
    if resp.status_code!=200:
        return f"后端请求失败: {resp.status_code} => {resp.text}"
    j = resp.json()
    results = j.get("results", [])
    if not results:
        return []
    vals = results[0].get("values", [])
    arr = []
    from datetime import datetime
    def parse_ts(s):
        try:
            dt = datetime.strptime(s,"%Y-%m-%d %H:%M:%S")
            return int(dt.timestamp())
        except:
            return 0
    for row in vals:
        if len(row)>=2:
            tstr,vstr = row[0], row[1]
            t = parse_ts(tstr)
            try:
                v = float(vstr)
            except:
                v = 0.0
            arr.append([t,v])
    return arr

def get_monitor_metric_value(ip, start, end, field):
    """
    start/end是 'YYYY-MM-DD HH:MM:SS' => 转成int => 读缓存 => 无则后端请求 => 写缓存 => 返回
    """
    import datetime
    def to_int(s):
        dt = datetime.datetime.strptime(s,"%Y-%m-%d %H:%M:%S")
        return int(dt.timestamp())
    st_i = to_int(start)
    et_i = to_int(end)
    fpath= _cache_filename(ip, st_i, et_i, field)
    if os.path.exists(fpath):
        print("(已从本地缓存读取)")
        return json.load(open(fpath,"r",encoding="utf-8"))
    else:
        data= fetch_data_from_backend(ip, st_i, et_i, field)
        if isinstance(data,str):
            return data
        with open(fpath,"w",encoding="utf-8") as f:
            json.dump(data,f,ensure_ascii=False,indent=2)
        print("(已调用后端并写入本地缓存)")
        return data

###############################################################################
# 三、用于(文件)单序列/多序列检测，并生成报告 & 可视化
###############################################################################

def single_series_detect(ip, field, start, end):
    series = get_monitor_metric_value(ip, start, end, field)
    if isinstance(series, str):
        return {"error": series}

    res = analyze_single_series(series)
    rep = generate_report_single(res, ip, field, start, end)
    html = generate_echarts_html_single(series, res["anomaly_times"])
    return {"analysis": res, "report": rep, "html": html}


def multi_series_detect(ip1, field1, start1, end1,
                        ip2, field2, start2, end2):
    s1 = get_monitor_metric_value(ip1, start1, end1, field1)
    if isinstance(s1, str):
        return {"error": s1}
    s2 = get_monitor_metric_value(ip2, start2, end2, field2)
    if isinstance(s2, str):
        return {"error": s2}

    res = analyze_multi_series(s1, s2)
    rep = generate_report_multi(res, ip1, field1, ip2, field2, start1, end1, start2, end2)
    html = generate_echarts_html_multi(s1, s2, res["anomaly_times"])
    return {"analysis": res, "report": rep, "html": html}


###############################################################################
# 四、LLM ReAct Agent
###############################################################################

def llm_call(messages):
    """
    向大模型发请求
    """
    data={
      "model":"Qwen2.5-14B-Instruct",
      "temperature":0.1,
      "messages":messages
    }
    r= requests.post(LLM_URL, json=data)
    if r.status_code==200:
        jj= r.json()
        if "choices" in jj and len(jj["choices"])>0:
            return jj["choices"][0]["message"]
        else:
            return None
    else:
        print("Error:", r.status_code, r.text)
        return None
    
def init_msg(role, content):
    return {"role": role, "content": content}



def parse_llm_response(txt):
    pat_thought = r"<思考过程>(.*?)</思考过程>"
    pat_action  = r"<工具调用>(.*?)</工具调用>"
    pat_inparam = r"<调用参数>(.*?)</调用参数>"
    pat_final   = r"<最终答案>(.*?)</最终答案>"
    def ext(pattern):
        m = re.search(pattern, txt, flags=re.S)
        return m.group(1) if m else ""

    return {
        "thought": ext(pat_thought),
        "action":  ext(pat_action),
        "action_input": ext(pat_inparam),
        "final_answer": ext(pat_final)
    }

def react(llm_text):
    parsed= parse_llm_response(llm_text)
    action= parsed["action"]
    inp_str= parsed["action_input"]
    final_ans= parsed["final_answer"]
    is_final= False

    if action and inp_str:
        # 解析调用参数
        try:
            action_input = json.loads(inp_str)
        except:
            return f"无法解析调用参数JSON: {inp_str}", False

        # 匹配action
        if action == "解析用户自然语言时间":
            return parse_time_expressions(action_input["raw_text"]), False
        elif action == "请求智能运管后端Api，获取指标项的时序数据":
            return get_monitor_metric_value(**action_input), False
        elif action == "请求智能运管后端Api，查询监控实例有哪些监控项":
            return monitor_item_list(action_input["instance"]), False
        elif action == "请求智能运管后端Api，查询监控服务的资产情况和监控实例":
            return get_service_asset(action_input["service"]), False
        elif action == "请求智能运管后端Api，查询监控实例之间的拓扑关联关系":
            return get_service_asset_edges(action_input["service"], action_input["instance_ip"]), False

        elif action == "单序列异常检测(文件)":
            return single_series_detect(**action_input), False

        elif action == "多序列对比异常检测(文件)":
            return multi_series_detect(**action_input), False

        else:
            return f"未知工具调用: {action}", False

    # 如果final_answer不为空，就返回并结束
    if final_ans.strip():
        is_final = True
        return (final_ans,is_final)

    return ("格式不符合要求，必须使用：<思考过程></思考过程> <工具调用></工具调用> <调用参数></调用参数> <最终答案></最终答案>", is_final)

def shorten_tool_result(res, max_len=300):
    """
    对工具返回结果做截断或简要摘要，避免在对话中携带过长文本。
    """
    if isinstance(res, list):
        return f"[List len={len(res)}] (showing 0)"
    elif isinstance(res, dict):
        summary = {}
        for k, v in res.items():
            if isinstance(v, list):
                summary[k] = f"[List len={len(v)}] (omitted)"
            elif isinstance(v, str) and len(v) > max_len:
                summary[k] = v[:max_len] + f"...(omitted, length={len(v)})"
            else:
                summary[k] = v
        return json.dumps(summary, ensure_ascii=False)
    elif isinstance(res, str) and len(res) > max_len:
        return res[:max_len] + f"...(omitted length={len(res)})"
    else:
        return str(res)


def chat(user_query):
    system_prompt = f'''你是一个严格遵守格式规范的用于运维功能，运维数据可视化，运行于生产环境的ReAct智能体，你叫小助手，必须按以下格式处理请求：

    你的工具列表如下:
    {json.dumps(tools, ensure_ascii=False, indent=2)}
    当前时间为: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

    处理规则：
    1.请根据当前时间来推断用户输入的时间区间的具体值
    2.如 parse_time_expressions 只返回1个时间区间，则调用'单序列异常检测(文件)'。
    3.如 parse_time_expressions 返回2个时间区间，并且用户输入包含"对比"、"相比"、"比较"、"环比"等比较词汇 ，则调用'多序列对比异常检测(文件)'。
    4.若有超过1个时间区间，但是没有明显的比较词汇，可先在<最终答案>里提问，示例:
    <思考过程>我不知道用户是要对这些时间的数据分别进行单序列分析还是一起多序列分析，我需要确认</思考过程> <工具调用></工具调用> <调用参数></调用参数> <最终答案>请问您是想对每段数据进行单序列分析，还是需要多序列的对比分析？</最终答案>
    5.根据用户的输入来自行判断是否要调用工具以及调用哪个工具
    4.每次只能调用一个工具
    5.不能伪造数据
    6.严格按照以下xml格式生成响应文本：
    ```
    <思考过程>你的思考过程</思考过程>
    <工具调用>工具名称，不调用则为空</工具调用>
    <调用参数>工具输入参数{{json}}</调用参数>
    <最终答案>用户问题的最终结果（知道问题的最终答案时返回）</最终答案>
    ```
    '''
    history=[]
    history.append({"role":"system","content":system_prompt})
    history.append({"role":"user","content": user_query})

    round_num=1
    max_round=15

    while True:
        print(f"=== 第{round_num}轮对话 ===")
        ans= llm_call(history)
        if not ans:
            print("大模型返回None,结束")
            return

        # 打印大模型完整响应 (JSON形式或content都可以)
        print("## 大模型完整响应:", ans)

        # 把响应加入history
        history.append(ans)

        txt= ans.get("content","")
        result, done= react(txt)

        # 对工具调用结果做截断后也放进对话上下文
        short_result = shorten_tool_result(result, max_len=300)
        history.append({
            "role":"user",
            "content": f"<工具调用结果>: {short_result}"
        })

        if done:
            print("===最终输出===")
            print(result)
            return

        round_num+=1
        if round_num>max_round:
            print("超出上限")
            return



if __name__ == '__main__':
    # chat('你好')
    chat(
        '我想查询192.168.0.110这台主机这周星期一和上周星期一的cpu利用率的对比，并给出echarts折线图的完整html，并进行分析给出分析报告')


# === config.py ===
# config.py

WEIGHTS_SINGLE = {
    "Z-Score": 0.3,
    "CUSUM":   0.3,
    "STL":     0.4
}

WEIGHTS_MULTI = {
    "ResidualComparison": 0.3,
    "TrendDriftCUSUM":    0.3,
    "ChangeRate":         0.2,
    "TrendSlope":         0.2
}

# 阈值：决定综合分数达到多少算高置信度异常
HIGH_ANOMALY_THRESHOLD = 0.7
MILD_ANOMALY_THRESHOLD = 0.4


# === output/report_generator.py ===
# output/report_generator.py
import datetime

def _fmt_ts(t_int):
    try:
        dt = datetime.datetime.fromtimestamp(t_int)
        return dt.strftime("%Y-%m-%d %H:%M:%S")
    except:
        return str(t_int)

def generate_report_single(results_dict, ip, field, start, end):
    lines=[]
    lines.append(f"【单序列异常检测报告】")
    lines.append(f"监控对象: IP={ip}, field={field}, 时间范围={start}~{end}")
    lines.append("检测方法及其结果:")
    for r in results_dict["method_results"]:
        lines.append(f"- {r['method']}: {r.get('description','')} (异常数={len(r['anomalies'])})")

    lines.append(f"综合评分: {results_dict['composite_score']:.2f}")
    lines.append(f"判定: {results_dict['classification']}")
    if results_dict["anomaly_times"]:
        lines.append("异常时间点:")
        for t in results_dict["anomaly_times"]:
            lines.append(f"  - {_fmt_ts(t)}")

    # 更多stats
    es = results_dict.get("extra_stats", {})
    mean_val = es.get("mean", None)
    std_val  = es.get("std", None)
    max_t    = es.get("max_time", None)
    max_v    = es.get("max_value", None)
    if mean_val is not None:
        lines.append(f"平均值: {mean_val:.3f}, 标准差: {std_val:.3f}")
    if max_t:
        lines.append(f"最大值出现在 {_fmt_ts(max_t)}, value={max_v:.3f}")

    return "\n".join(lines)

def generate_report_multi(results_dict, ip1, field1, ip2, field2,
                          start1, end1, start2, end2):
    lines=[]
    lines.append("【多序列对比异常检测报告】")
    lines.append(f"第一组: IP={ip1}, field={field1}, 时间范围={start1}~{end1}")
    lines.append(f"第二组: IP={ip2}, field={field2}, 时间范围={start2}~{end2}")

    lines.append("检测方法及结果:")
    for r in results_dict["method_results"]:
        lines.append(f"- {r['method']}: {r.get('description','')} (异常数={len(r['anomalies'])})")

    lines.append(f"综合评分: {results_dict['composite_score']:.2f}")
    lines.append(f"分类: {results_dict['classification']}")

    anoms = results_dict["anomaly_times"]
    if anoms:
        lines.append("异常时间点(仅显示前20个):")
        for t in anoms[:20]:
            lines.append(f"  - {_fmt_ts(t)}")
        if len(anoms) > 20:
            lines.append(f"... 共 {len(anoms)} 个异常点，后续省略 ...")
    else:
        lines.append("异常时间点: 无")

    # 额外stats
    es = results_dict.get("extra_stats",{})
    mean1= es.get("mean1",0)
    mean2= es.get("mean2",0)
    max_diff_t= es.get("max_diff_time", None)
    max_diff_v= es.get("max_diff_value", None)
    lines.append(f"第一组均值: {mean1:.3f}, 第二组均值: {mean2:.3f}")
    if max_diff_t is not None:
        lines.append(f"最大差值出现在 {_fmt_ts(max_diff_t)}, 差值= {max_diff_v:.3f}")

    # 这里可以再做一个 prompt 给大模型进行“润色”
    # 省略

    return "\n".join(lines)


# === output/visualization.py ===
# output/visualization.py
import json

def generate_echarts_html_single(series, anomalies=None):
    """
    series: [ [int_ts, val], ... ]
    anomalies: [ t_int, ... ]
    """
    if anomalies is None:
        anomalies=[]
    data_points = []
    anomaly_points=[]
    for (t,v) in series:
        data_points.append([t*1000, v])
        if t in anomalies:
            anomaly_points.append({"coord":[t*1000,v], "name":"异常"})

    option = {
        "title":{"text":"单序列折线图"},
        "tooltip":{"trigger":"axis"},
        "xAxis":{"type":"time"},
        "yAxis":{"type":"value"},
        "series":[
            {
              "name":"值",
              "type":"line",
              "data": data_points,
              "markPoint":{"data": anomaly_points}
            }
        ]
    }
    html = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Single Series ECharts</title>
    <script src="https://cdn.jsdelivr.net/npm/echarts/dist/echarts.min.js"></script>
</head>
<body>
<div id="chart" style="width:800px; height:400px;"></div>
<script>
var chart = echarts.init(document.getElementById('chart'));
var option = {json.dumps(option, ensure_ascii=False)};
chart.setOption(option);
</script>
</body>
</html>
"""
    return html

def generate_echarts_html_multi(series1, series2, anomalies=None):
    """
    两条线
    series1, series2 => [ [t,val], ...]
    anomalies => union of anomaly times
    """
    if anomalies is None:
        anomalies=[]
    # prepare
    data1=[]
    data2=[]
    mark_points=[]
    for (t,v) in series1:
        data1.append([t*1000, v])
        if t in anomalies:
            mark_points.append({"coord":[t*1000, v], "name":"异常"})
    for (t,v) in series2:
        data2.append([t*1000, v])
        if t in anomalies:
            mark_points.append({"coord":[t*1000, v], "name":"异常"})

    option = {
        "title":{"text":"多序列对比折线图"},
        "tooltip":{"trigger":"axis"},
        "legend":{"data":["序列1","序列2"]},
        "xAxis":{"type":"time"},
        "yAxis":{"type":"value"},
        "series":[
            {
              "name":"序列1",
              "type":"line",
              "data":data1,
              "markPoint":{"data": mark_points}
            },
            {
              "name":"序列2",
              "type":"line",
              "data":data2,
              "markPoint":{"data": mark_points}
            }
        ]
    }
    html = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Multi Series ECharts</title>
    <script src="https://cdn.jsdelivr.net/npm/echarts/dist/echarts.min.js"></script>
</head>
<body>
<div id="chart" style="width:800px; height:400px;"></div>
<script>
var chart = echarts.init(document.getElementById('chart'));
var option = {json.dumps(option, ensure_ascii=False)};
chart.setOption(option);
</script>
</body>
</html>
"""
    return html


# === test/mail_test.py ===
#! /usr/bin/env python3
import re
import json
import datetime
import requests
from django.conf import settings

AIOPS_BACKEND_DOMAIN = 'https://aiopsbackend.cstcloud.cn'
LLM_URL = 'http://10.16.1.16:58000/v1/chat/completions'

AUTH = ('chelseyyycheng@outlook.com', 'UofV1uwHwhVp9tcTue')

tools = [
    {
        "type": "function",
        "function": {
            "name": "请求智能运管后端Api，获取指标项的时序数据",
            "description": "请求智能运管后端Api，获取指标项的时序数据",
            "parameters": {
                "type": "object",
                "properties": {
                    "ip": {
                        "type": "string",
                        "description": "要查询的ip"
                    },
                    "start": {
                        "type": "string",
                        "description": "日期，格式为 Y-%m-%d %H:%M:%S"
                    },
                    "end": {
                        "type": "string",
                        "description": "日期，格式为 Y-%m-%d %H:%M:%S"
                    },
                    "field": {
                        "type": "string",
                        "description": "监控项名称，只可在监控项列表中选择"
                    },
                },
                "required": ["ip", "start", "end", "field"],
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "请求智能运管后端Api，查询监控实例有哪些监控项",
            "description": "请求智能运管后端Api，查询监控实例有哪些监控项",
            "parameters": {
                "type": "object",
                "properties": {
                    "service": {
                        "type": "string",
                        "description": "要查询的系统名称"
                    },
                    "instance": {
                        "type": "string",
                        "description": "要查询的监控实例"
                    },
                },
                "required": ["service", "instance"],

            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "请求智能运管后端Api，查询监控实例之间的拓扑关联关系",
            "description": "监控实例上联了哪些监控实例列表，下联了哪些监控实例列表",
            "parameters": {
                "type": "object",
                "properties": {
                    "service": {
                        "type": "string",
                        "description": "要查询的系统名称"
                    },
                    "instance_ip": {
                        "type": "string",
                        "description": "要查询的监控实例的IP地址"
                    },
                },
                "required": ["service", 'instance_ip'],
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "请求智能运管后端Api，查询监控服务的资产情况和监控实例",
            "description": "请求智能运管后端Api，查询监控服务的资产情况和监控实例",
            "parameters": {
                "type": "object",
                "properties": {
                    "service": {
                        "type": "string",
                        "description": "要查询的系统名称"
                    },
                },
                "required": ["service"],

            }
        }
    },

]


def monitor_item_list(ip):
    url = f'{AIOPS_BACKEND_DOMAIN}/api/v1/monitor/mail/machine/field/?instance={ip}'
    resp = requests.get(url=url, auth=AUTH)
    text = json.loads(resp.text)
    result = dict()
    if resp.status_code == 200:
        for item in text:
            result[item.get('field')] = item.get('purpose')
        return result
    else:
        return text


def get_service_asset(service):
    url = f'{AIOPS_BACKEND_DOMAIN}/api/v1/property/mail/?ordering=num_id&page=1&page_size=2000'
    resp = requests.get(url=url, auth=AUTH)
    text = json.loads(resp.text)
    results = text.get('results')
    item_list = []
    for _ in results:
        _['category'] = _.get('category').get('name')
        _["ip_set"] = [_.get("ip") for _ in _.get('ip_set')]
        _.pop('num_id')
        _.pop('creation')
        _.pop('modification')
        _.pop('remark')
        _.pop('sort_weight')
        _.pop('monitor_status')
        for k, v in _.copy().items():
            if not v or v == '无':
                _.pop(k)
        item_list.append(_)
    return item_list


def get_service_asset_edges(service, instance_ip):
    url = f'{AIOPS_BACKEND_DOMAIN}/api/v1/property/mail/topology/search?instance={instance_ip}'
    resp = requests.get(url=url, auth=AUTH)
    text = json.loads(resp.text)
    # print(text)
    return text


def get_monitor_metric_value(ip, start, end, field):
    metric_field_list = monitor_item_list(ip)
    if field not in metric_field_list.keys():
        return f"未知的监控项：{field}"
    # 查询监控指标情况
    start_timestamp = datetime.datetime.strptime(start, "%Y-%m-%d %H:%M:%S").timestamp()
    end_timestamp = datetime.datetime.strptime(end, "%Y-%m-%d %H:%M:%S").timestamp()
    url = f'{AIOPS_BACKEND_DOMAIN}/api/v1/monitor/mail/metric/format-value/?start={start_timestamp}&end={end_timestamp}&instance={ip}&field={field}'
    resp = requests.get(url=url, auth=AUTH)
    text = resp.text
    text = json.loads(text)
    return text


# ------------------------------------------------------------------------


def llm_call(messages):
    # for _ in messages:
    #     print(_)
    #     print('\n')
    data = {
        "model": "Qwen2.5-14B-Instruct",
        "temperature": 0.1,
        "messages": messages,
    }
    response = requests.post(LLM_URL, json=data)
    if response.status_code == 200:
        response_data = response.json()
        if 'choices' in response_data and len(response_data['choices']) > 0:
            generated_content = response_data['choices'][0]['message']['content']
            # print('##Token使用情况##:\n\n', response_data['usage'])
            # print('------------------\n\n')
            return response_data['choices'][0]['message']
        else:
            print(response_data)
            raise Exception("模型没有返回信息")
    else:
        print(f'Error: {response.status_code}')
        print(response.text)


def init_message_by_role(role, content):
    message = {
        'role': role,
        "content": content
    }
    return message


def parse_llm_response(llm_resp_content):
    invalid_value = ["空", '无']
    thought_match = re.search(r'<思考过程>(.*)</思考过程>', llm_resp_content, re.S)
    if thought_match and thought_match[0] not in invalid_value:
        thought = thought_match.group(1)
    else:
        thought = ""
    action_match = re.search(r'<工具调用>(.*)</工具调用>', llm_resp_content)
    if action_match and action_match[0] not in invalid_value:
        action = action_match.group(1)
    else:
        action = ""
    action_input_match = re.search(r'<调用参数>(.*)</调用参数>', llm_resp_content)
    if action_input_match and action_input_match[0] not in invalid_value:
        action_input = action_input_match.group(1)
    else:
        action_input = ""
    if "<最终答案>" in llm_resp_content and "</最终答案>" not in llm_resp_content:
        llm_resp_content += "</最终答案>"
    final_answer_match = re.search(r'<最终答案>(.*)</最终答案>', llm_resp_content, re.S)
    if final_answer_match and final_answer_match[0] not in invalid_value:
        final_answer = final_answer_match.group(1)
    else:
        final_answer = ""
    result = {
        'thought': thought,
        'action': action,
        'action_input': action_input,
        'final_answer': final_answer,
    }
    return result


def react(llm_resp_content):
    is_final = False
    llm_parsed_dict = parse_llm_response(llm_resp_content)
    # print("##解析后的参数", llm_parsed_dict)
    action = llm_parsed_dict.get('action')
    action_input = llm_parsed_dict.get('action_input')
    final_answer = llm_parsed_dict.get('final_answer')
    # print("当前的大模型解析", llm_parsed_dict)
    if action and action_input:
        # print("##调用函数##", action, action_input)
        action_input = json.loads(action_input)
        if action == '请求智能运管后端Api，获取指标项的时序数据':
            return get_monitor_metric_value(**action_input), is_final
        if action == '请求智能运管后端Api，查询监控实例有哪些监控项':
            return monitor_item_list(action_input.get('instance')), is_final
        if action == '请求智能运管后端Api，查询监控服务的资产情况和监控实例':
            return get_service_asset(action_input.get('service')), is_final
        if action == "请求智能运管后端Api，查询监控实例之间的拓扑关联关系":
            return get_service_asset_edges(**action_input), is_final
    if final_answer:
        is_final = True
        return final_answer, is_final
    else:
        result = """
生成的文本格式有误，严格按照以下指定格式生成响应：
```
<思考过程>你的思考过程</思考过程>
<工具调用>工具名称（必须是{tool_names}之一），如果不调用工具，则为空</工具调用>
<调用参数>工具输入参数（严格符合工具描述格式）</调用参数>
<最终答案>用户问题的最终结果（知道问题的最终答案时返回）</最终答案>
```
"""
        return result, is_final


def stream_response_format(category, content):
    data = f'data: {json.dumps({category: content}, ensure_ascii=False)}\n\n'
    return data


def chat(user_content):
    system_template = '''你是一个严格遵守格式规范的用于运维功能，运维数据可视化，运行于生产环境的ReAct智能体，你叫小助手，必须按以下格式处理请求：

    可用工具：
    {tools}

    处理规则：
    1.根据用户的问题来自行判断是否要调用工具以及调用哪个工具
    2.每次只能调用一个工具
    3.不能伪造数据
    3.严格按照以下xml格式生成响应文本：
    ```
    <思考过程>你的思考过程</思考过程>
    <工具调用>工具名称（必须是{tool_names}之一），如果不调用工具，则为空</工具调用>
    <调用参数>工具输入参数（严格符合工具描述格式）</调用参数>
    <最终答案>用户问题的最终结果（知道问题的最终答案时返回）</最终答案>
    ```
    '''
    history = list()
    history.append(init_message_by_role(
        role='system',
        content=system_template.format(
            tools=json.dumps(tools, ensure_ascii=False),
            tool_names=json.dumps([tool["function"]["name"] for tool in tools], ensure_ascii=False), )
    ))
    current_datetime = str(datetime.datetime.now()).split('.')[0]
    history.append(init_message_by_role(role='user', content=f'当前时间是 {current_datetime}'))
    history.append(init_message_by_role(role='user', content=user_content))
    count = 1
    while True:
        print(f'第{count}次循环')
        llm_resp_message = llm_call(history)
        print('##大模型响应##', llm_resp_message)
        history.append(llm_resp_message)
        response, is_final_flag = react(llm_resp_message.get('content'))
        history.append(init_message_by_role(role='user', content=f"<工具调用结果>: {response}</工具调用结果>"))
        if is_final_flag:
            print(response)
            return
        count += 1
        if count >= 15:
            response = llm_resp_message.get('content')
            print(response)
            return


if __name__ == '__main__':
    # chat('你好')
    chat(
        '我想查询邮件系统 192.168.0.110 这台主机今天1点到1点30分的cpu利用率，并给出echarts折线图的完整html，并进行分析给出分析报告')


# === analysis/multi_series.py ===
# 文件: analysis/multi_series.py

import config
from detectors import residual_compare_detector, trend_drift_detector, change_rate_detector, trend_slope_detector
from analysis.data_alignment import align_series

def analyze_multi_series(series1, series2, align=True):
    """
    对两组时序进行多方法对比异常检测；可在内部先插值对齐(align_series)再检测。
    series1, series2: list of [int_ts, float_val]
    align: bool, 是否先做插值对齐
    
    返回 dict:
    {
      "method_results": [...],
      "composite_score": 0.65,
      "classification": "轻度异常",
      "anomaly_times": [...]
    }
    """
    # 1) 先可选插值对齐
    if align:
        series1, series2 = align_series(series1, series2, method="linear", fill_value="extrapolate")

    # 2) 调用多种方法
    res_residual = residual_compare_detector.detect_residual_compare(series1, series2)
    res_drift    = trend_drift_detector.detect_trend_drift(series1, series2)
    res_change   = change_rate_detector.detect_change_rate(series1, series2)
    res_slope    = trend_slope_detector.detect_trend_slope(series1, series2)

    method_results = [res_residual, res_drift, res_change, res_slope]

    # 3) 计算加权综合评分
    total_weight = 0.0
    composite_score = 0.0
    length = max(len(series1), len(series2)) or 1

    for res in method_results:
        m_name = res["method"]
        weight = config.WEIGHTS_MULTI.get(m_name, 0.0)
        total_weight += weight

        anomalies_count = len(res["anomalies"])
        method_score = anomalies_count / length
        if 0 < method_score < 0.1:
            method_score = 0.1

        composite_score += weight * method_score

    if total_weight > 0:
        composite_score /= total_weight

    if composite_score >= config.HIGH_ANOMALY_THRESHOLD:
        classification = "高置信度异常"
    elif composite_score >= config.MILD_ANOMALY_THRESHOLD:
        classification = "轻度异常"
    else:
        classification = "正常"

    # 合并 anomalies
    all_anoms = set()
    for r in method_results:
        for ts in r["anomalies"]:
            all_anoms.add(ts)

    return {
        "method_results": method_results,
        "composite_score": composite_score,
        "classification": classification,
        "anomaly_times": sorted(all_anoms)
    }


# === analysis/data_alignment.py ===
# 文件: analysis/data_alignment.py
import numpy as np
from scipy.interpolate import interp1d

def align_series(series1, series2, method="linear", fill_value="extrapolate"):
    """
    使用SciPy的interp1d进行插值，将series1和series2在相同的时间戳上对齐。
    
    Parameters
    ----------
    series1 : list of [int_ts, val]
    series2 : list of [int_ts, val]
    method  : str, 插值方法，可选 'linear', 'nearest', 'cubic' 等
    fill_value: str or float, 边界填充值,可 'extrapolate' 或一个常数

    Returns
    -------
    s1_aligned, s2_aligned : 两个对齐后的序列 (list of [int_ts, val])
        对齐后时间戳 = 两个序列所有时间戳的并集 + 指定插值方法
    """
    if not series1 or not series2:
        # 若其中一个为空，则原样返回
        return series1, series2

    # 1) 排序并拆成np.array
    s1_sorted = sorted(series1, key=lambda x: x[0])
    s2_sorted = sorted(series2, key=lambda x: x[0])

    t1 = np.array([row[0] for row in s1_sorted], dtype=np.float64)
    v1 = np.array([row[1] for row in s1_sorted], dtype=np.float64)
    t2 = np.array([row[0] for row in s2_sorted], dtype=np.float64)
    v2 = np.array([row[1] for row in s2_sorted], dtype=np.float64)

    # 2) 取并集时间戳
    all_ts = np.union1d(t1, t2)

    # 3) 建立插值函数
    f1 = interp1d(t1, v1, kind=method, fill_value=fill_value, bounds_error=False)
    f2 = interp1d(t2, v2, kind=method, fill_value=fill_value, bounds_error=False)

    # 4) 对并集时间戳插值
    new_v1 = f1(all_ts)
    new_v2 = f2(all_ts)

    # 5) 返回对齐结果
    s1_aligned = [[int(ts), float(val)] for ts, val in zip(all_ts, new_v1)]
    s2_aligned = [[int(ts), float(val)] for ts, val in zip(all_ts, new_v2)]

    return s1_aligned, s2_aligned


# === analysis/single_series.py ===
# 文件: analysis/single_series.py

import config
from detectors import zscore_detector, cusum_detector, stl_detector

def analyze_single_series(series):
    """
    对单序列时序数据进行异常检测，调用Z-Score、CUSUM、STL等方法并融合结果。
    series: list of [int_ts, float_val], 已按时间排序或未排序皆可(内部方法会自行处理)
    
    返回 dict:
    {
      "method_results": [
         { "method":"Z-Score", "anomalies":[...], "scores":[...], "description":"..." },
         { "method":"CUSUM",   ... },
         { "method":"STL",     ... },
      ],
      "composite_score": 0.55,
      "classification": "轻度异常",
      "anomaly_times": [...]
    }
    """
    # 分别调用三个检测器
    res_z     = zscore_detector.detect_zscore(series)
    res_cusum = cusum_detector.detect_cusum(series)
    res_stl   = stl_detector.detect_stl_residual(series)

    method_results = [res_z, res_cusum, res_stl]

    # 计算加权综合评分
    total_weight = 0.0
    composite_score = 0.0
    length = len(series) if series else 1

    for res in method_results:
        m_name = res["method"]
        weight = config.WEIGHTS_SINGLE.get(m_name, 0.0)
        total_weight += weight

        anomalies_count = len(res["anomalies"])
        method_score = anomalies_count / length
        # 让方法分数最小值0.1 => 避免特别小分数被忽视
        if 0 < method_score < 0.1:
            method_score = 0.1

        composite_score += weight * method_score

    if total_weight > 0:
        composite_score /= total_weight

    # 根据score判断分类
    if composite_score >= config.HIGH_ANOMALY_THRESHOLD:
        classification = "高置信度异常"
    elif composite_score >= config.MILD_ANOMALY_THRESHOLD:
        classification = "轻度异常"
    else:
        classification = "正常"

    # 合并 anomalies
    all_anomalies = set()
    for r in method_results:
        for ts in r["anomalies"]:
            all_anomalies.add(ts)

    return {
        "method_results": method_results,
        "composite_score": composite_score,
        "classification": classification,
        "anomaly_times": sorted(all_anomalies)
    }


# === detectors/change_rate_detector.py ===
# 文件: detectors/change_rate_detector.py

def detect_change_rate(series1, series2, threshold=0.5):
    """
    对比两序列在相同时间戳上的变化率。
    threshold: 当两者的变化率之差大于该值则视为异常
    """
    if not series1 or not series2:
        return {
            "method":"ChangeRate",
            "anomalies":[],
            "scores":[],
            "description":"数据不足"
        }
    dict2 = {row[0]:row[1] for row in series2}
    s1_sorted = sorted(series1,key=lambda x:x[0])
    anomalies=[]
    scores=[]
    prev_v1=None
    prev_v2=None
    prev_ts=None
    for (ts,v1) in s1_sorted:
        if ts in dict2:
            v2 = dict2[ts]
            if prev_v1 is not None and prev_v2 is not None and abs(prev_v1)>1e-9 and abs(prev_v2)>1e-9:
                rate1 = (v1 - prev_v1)/abs(prev_v1)
                rate2 = (v2 - prev_v2)/abs(prev_v2)
                diff = abs(rate1-rate2)
                if diff>threshold:
                    anomalies.append(ts)
                    scores.append(diff)
            prev_v1=v1
            prev_v2=v2
            prev_ts=ts
    desc = f"变化率检测到{len(anomalies)}个异常" if anomalies else "未发现变化率异常"
    return {
        "method":"ChangeRate",
        "anomalies":anomalies,
        "scores":scores,
        "description":desc
    }


# === detectors/zscore_detector.py ===
# 文件: detectors/zscore_detector.py
import statistics

def detect_zscore(series, threshold=3.0):
    """
    使用Z-Score方法全局检测离群点。
    series: list of [ts, val], ts为int秒, val为float
    threshold: 超过多少σ才视为异常,默认为3
    """
    if not series:
        return {
            "method":"Z-Score",
            "anomalies":[],
            "scores":[],
            "description":"无数据"
        }

    vals = [row[1] for row in series]
    mean_val = statistics.mean(vals)
    stdev_val = statistics.pstdev(vals)
    if stdev_val == 0:
        return {
            "method":"Z-Score",
            "anomalies":[],
            "scores":[],
            "description":"方差=0,无显著波动"
        }

    anomalies = []
    scores = []
    for (ts, val) in series:
        z = (val - mean_val)/stdev_val
        if abs(z) > threshold:
            anomalies.append(ts)
            scores.append(abs(z))

    desc = f"Z-Score检测到{len(anomalies)}个> {threshold}σ的异常点." if anomalies else "未发现Z-Score异常"
    return {
        "method":"Z-Score",
        "anomalies": anomalies,
        "scores": scores,
        "description": desc
    }


# === detectors/stl_detector.py ===
# 文件: detectors/stl_detector.py

import math
try:
    from statsmodels.tsa.seasonal import STL
except ImportError:
    STL = None

def detect_stl_residual(series, period=None):
    """
    使用STL分解（若可用），分析残差异常。
    series: list of [ts, val]
    period: 季节期(若无则可设None)
    """
    if not series:
        return {
            "method":"STL",
            "anomalies":[],
            "scores":[],
            "description":"无数据"
        }
    values = [row[1] for row in series]
    n = len(values)
    if n < 3:
        return {
            "method":"STL",
            "anomalies":[],
            "scores":[],
            "description":"数据点太少"
        }
    # 如 period 未指定,可默认=7等. 这里仅演示:
    if not period:
        period = 24  # 如果是一天周期之类

    anomalies = []
    scores = []

    # 若statsmodels没装或period不合理 => 做个简化
    if STL is None or period>=n:
        # 简单移动平均
        window = max(1, min(n//5,10))
        trend = []
        for i in range(n):
            left_i = max(0,i-window)
            right_i= min(n,i+window+1)
            sub= values[left_i:right_i]
            trend_val = sum(sub)/len(sub)
            trend.append(trend_val)
        resid = [v - t for v,t in zip(values,trend)]
    else:
        stl = STL(values, period=period, robust=True)
        res = stl.fit()
        resid = res.resid

    # 分析 resid => zscore
    from statistics import mean, pstdev
    m = mean(resid)
    s = pstdev(resid)
    if s==0:
        return {
            "method":"STL",
            "anomalies":[],
            "scores":[],
            "description":"STL残差无波动"
        }
    threshold = 3
    for i, r_val in enumerate(resid):
        if abs(r_val-m)>threshold*s:
            anomalies.append(series[i][0])
            scores.append(abs(r_val-m)/s - threshold)
    desc = f"STL分解残差发现{len(anomalies)}个>3σ异常点" if anomalies else "未见STL异常"
    return {
        "method":"STL",
        "anomalies": anomalies,
        "scores": scores,
        "description": desc
    }


# === detectors/trend_slope_detector.py ===
# 文件: detectors/trend_slope_detector.py

def detect_trend_slope(series1, series2, window=5, slope_threshold=0.5):
    """
    滑动窗口对比两个序列的局部斜率差异
    window: 窗口大小(数据点数)
    slope_threshold: 当斜率比差距大于此阈值则异常
    """
    if not series1 or not series2:
        return {
            "method":"TrendSlope",
            "anomalies":[],
            "scores":[],
            "description":"数据不足"
        }
    dict2 = {row[0]:row[1] for row in series2}
    s1_sorted = sorted(series1,key=lambda x:x[0])

    anomalies=[]
    scores=[]
    # 用window做局部斜率
    for i in range(len(s1_sorted)-window+1):
        segment1 = s1_sorted[i:i+window]
        # 同步 segment2
        seg2 = []
        for (ts,v1) in segment1:
            if ts in dict2:
                seg2.append((ts, dict2[ts]))
        if len(seg2)<2:
            continue
        # slope1
        slope1 = (segment1[-1][1]-segment1[0][1])/(window-1)
        slope2 = (seg2[-1][1]-seg2[0][1])/(len(seg2)-1)
        ratio = 0.0
        if abs(slope1)>1e-9 and abs(slope2)>1e-9:
            ratio = abs(slope1-slope2)/max(abs(slope1),abs(slope2))
        if ratio> slope_threshold:
            anomalies.append(segment1[-1][0])
            scores.append(ratio)
    desc = f"趋势斜率对比发现{len(anomalies)}处异常" if anomalies else "趋势斜率基本一致"
    return {
        "method":"TrendSlope",
        "anomalies":anomalies,
        "scores":scores,
        "description":desc
    }


# === detectors/__init__.py ===


# === detectors/residual_compare_detector.py ===
# 文件: detectors/residual_compare_detector.py

import statistics

def detect_residual_compare(series1, series2, threshold=3.0):
    """
    两序列做差 => 分析(离群).
    (可认为是"残差对比",非常简化)
    threshold: 超过mean±threshold*stdev则异常
    """
    if not series1 or not series2:
        return {
            "method":"ResidualComparison",
            "anomalies":[],
            "scores":[],
            "description":"无数据或序列为空"
        }
    # 要对齐
    # (若multi_series里已对齐,这里只简单按ts查找)
    dict2 = {row[0]: row[1] for row in series2}
    diffs = []
    common_ts = []
    for (ts, v1) in series1:
        if ts in dict2:
            diffs.append(v1 - dict2[ts])
            common_ts.append(ts)
    if not diffs:
        return {
            "method":"ResidualComparison",
            "anomalies":[],
            "scores":[],
            "description":"两序列无重叠时间戳"
        }
    m = statistics.mean(diffs)
    s = statistics.pstdev(diffs) if len(diffs)>1 else 0
    if s==0:
        return {
            "method":"ResidualComparison",
            "anomalies":[],
            "scores":[],
            "description":"残差无波动"
        }
    anomalies = []
    scores = []
    for i, d in enumerate(diffs):
        if abs(d-m) > threshold*s:
            anomalies.append(common_ts[i])
            scores.append(abs(d-m)/s)
    desc = f"残差比较发现{len(anomalies)}个离群点" if anomalies else "未见残差异常"
    return {
        "method":"ResidualComparison",
        "anomalies":anomalies,
        "scores":scores,
        "description":desc
    }


# === detectors/trend_drift_detector.py ===
# 文件: detectors/trend_drift_detector.py

def detect_trend_drift(series1, series2, drift_threshold=5.0):
    """
    将两序列做差 => CUSUM => 看是否有趋势漂移
    """
    if not series1 or not series2:
        return {
            "method":"TrendDriftCUSUM",
            "anomalies":[],
            "scores":[],
            "description":"无数据"
        }
    # 同样先对齐
    dict2 = {row[0]: row[1] for row in series2}
    diffs=[]
    ts_list=[]
    for (ts,v1) in series1:
        if ts in dict2:
            diffs.append(v1 - dict2[ts])
            ts_list.append(ts)
    if not diffs:
        return {
            "method":"TrendDriftCUSUM",
            "anomalies":[],
            "scores":[],
            "description":"序列无对齐"
        }
    pos_sum=0.0
    neg_sum=0.0
    anomalies=[]
    scores=[]
    for i, d in enumerate(diffs):
        pos_sum = max(0, pos_sum+d)
        neg_sum = min(0, neg_sum+d)
        if pos_sum>drift_threshold or neg_sum<-drift_threshold:
            anomalies.append(ts_list[i])
            scores.append(abs(pos_sum) if abs(pos_sum)>abs(neg_sum) else abs(neg_sum))
            pos_sum=0
            neg_sum=0
    desc = f"趋势漂移检测到{len(anomalies)}处超阈值" if anomalies else "未见明显趋势漂移"
    return {
        "method":"TrendDriftCUSUM",
        "anomalies":anomalies,
        "scores":scores,
        "description":desc
    }


# === detectors/cusum_detector.py ===
# 文件: detectors/cusum_detector.py

def detect_cusum(series, drift_threshold=5.0):
    """
    使用CUSUM算法检测趋势漂移.
    drift_threshold: 超过该累计偏差则视为异常

    series: list of [ts, val]
    return: { "method":"CUSUM", "anomalies":[...], "scores":[...], "description":... }
    """
    if not series:
        return {
            "method":"CUSUM",
            "anomalies":[],
            "scores":[],
            "description":"无数据"
        }
    vals = [row[1] for row in series]
    mean_val = sum(vals)/len(vals)
    pos_sum = 0.0
    neg_sum = 0.0
    anomalies = []
    scores = []
    for i, (ts, val) in enumerate(series):
        diff = val - mean_val
        pos_sum = max(0, pos_sum+diff)
        neg_sum = min(0, neg_sum+diff)
        # 超过阈值 => 异常
        if pos_sum > drift_threshold or neg_sum < -drift_threshold:
            anomalies.append(ts)
            score = abs(pos_sum) if abs(pos_sum)>abs(neg_sum) else abs(neg_sum)
            scores.append(score)
            pos_sum = 0
            neg_sum = 0
    desc = f"CUSUM检测到{len(anomalies)}个疑似趋势漂移异常." if anomalies else "未见CUSUM异常"
    return {
        "method":"CUSUM",
        "anomalies": anomalies,
        "scores": scores,
        "description": desc
    }


# === detectors/ttest_detector.py ===
# detectors/ttest_detector.py
import statistics, math

def detect_ttest(series):
    """
    对单序列做某种T检验,演示
    """
    if not series:
        return {"method":"TTest","anomalies":[],"scores":[],"description":"无数据"}
    vals= [v for (_,v) in series]
    meanv= statistics.mean(vals)
    stdev= statistics.pstdev(vals) if len(vals)>1 else 0
    n= len(vals)
    if stdev==0 or n<2:
        return {"method":"TTest","anomalies":[],"scores":[],"description":"无法t检验"}
    t_stat= meanv/(stdev/ math.sqrt(n))
    # 仅演示fake p
    p= 2* math.exp(-abs(t_stat))
    if p<0.05:
        anoms= [ts for (ts,_) in series]  # 全异常(纯演示)
        desc= f"T检验:t={t_stat:.2f},p={p:.3f}=>显著"
    else:
        anoms=[]
        desc= f"T检验:t={t_stat:.2f},p={p:.3f}=>不显著"
    return {
      "method":"TTest",
      "anomalies": anoms,
      "scores":[],
      "description": desc
    }

def detect_ttest_2samples(series1, series2):
    """
    对比两序列 => t检验
    """
    if not series1 or not series2:
        return {"method":"TTest2","anomalies":[],"scores":[],"description":"无数据"}
    v1= [v for (_,v) in series1]
    v2= [v for (_,v) in series2]
    mean1= statistics.mean(v1)
    mean2= statistics.mean(v2)
    var1= statistics.pvariance(v1)
    var2= statistics.pvariance(v2)
    n1= len(v1)
    n2= len(v2)
    # pool var
    if n1+n2<3:
        return {"method":"TTest2","anomalies":[],"scores":[],"description":"样本过少"}
    sp= math.sqrt(((n1-1)*var1+(n2-1)*var2)/(n1+n2-2)) if (n1+n2>2) else 0
    if sp==0:
        return {"method":"TTest2","anomalies":[],"scores":[],"description":"方差=0?"}
    t_stat= (mean1- mean2)/(sp* math.sqrt(1/n1+1/n2))
    p= 2* math.exp(-abs(t_stat))
    desc= f"双样本T检验:t={t_stat:.2f},p={p:.3f}"
    anomalies=[]
    if p<0.05:
        # 全异常
        all_ts= set(ts for (ts,_) in series1).union(ts for (ts,_) in series2)
        anomalies= sorted(all_ts)
        desc+= "=>显著差异"
    else:
        desc+= "=>无显著差异"
    return {
      "method":"TTest2",
      "anomalies": anomalies,
      "scores":[],
      "description": desc
    }


# === storage/database.py ===
import json
import config
try:
    import pymysql
except ImportError:
    pymysql = None

def save_analysis_record(record):
    """
    保存分析记录到 MySQL 数据库。
    record: dict 包含 ip, field, start_time, end_time, methods, anomalies, composite_score, classification, report 等
    """
    ip = record.get("ip")
    field = record.get("field")
    start = record.get("start_time")
    end = record.get("end_time")
    methods = record.get("methods")
    anomalies = record.get("anomaly_times")
    composite_score = record.get("composite_score")
    classification = record.get("classification")
    report = record.get("report")
    methods_json = json.dumps(methods, ensure_ascii=False)
    anomalies_json = json.dumps(anomalies, ensure_ascii=False)
    insert_sql = (
        "INSERT INTO anomaly_analysis_records "
        "(ip, field, start_time, end_time, methods, anomalies, composite_score, classification, report) "
        "VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)"
    )
    values = (ip, field, start, end, methods_json, anomalies_json, composite_score, classification, report)
    try:
        if pymysql is None:
            from django.db import connection
            with connection.cursor() as cursor:
                cursor.execute(insert_sql, values)
                connection.commit()
        else:
            conn = pymysql.connect(host=config.DB_CONFIG['HOST'],
                                   port=config.DB_CONFIG['PORT'],
                                   user=config.DB_CONFIG['USER'],
                                   password=config.DB_CONFIG['PASSWORD'],
                                   database=config.DB_CONFIG['NAME'],
                                   charset='utf8mb4')
            cursor = conn.cursor()
            cursor.execute(insert_sql, values)
            conn.commit()
            cursor.close()
            conn.close()
    except Exception as e:
        print(f"保存记录失败: {e}")


